## OVERVIEW
- SemanticMap 使用一组 POI 和特定的城市绩效指标作为输入，生成城市绩效指标的连续密度图（定义为语义地图）。**七项城市绩效指标**：舒适性、宜居性、便利性、流动性，经济活力，交通安全，老年友善。此外，我们添加浪漫是为了分析人类对其居住区的完全主观感知。
- 使用上海地图，使用流量分析区域（TAZ）作为基本单元来分析本地 POI 密度，并在生成语义地图时自适应设置 KDE 参数。 **TAZ是城市地理单元的基本街区**，具有相似的社会经济和人口特征，常用于城市研究和交通研究[72]。图 2.A 显示了我们研究中使用的 TAZ 边界。如图所示，由于城市形态和道路网络更加复杂，城市中心区的TAZ比周边地区更密集。 TAZ 的使用为不同城市地区的 KDE 参数选择提供了适当的灵活性，以适应城市形态的复杂变化。在生成语义地图时，我们将图像分辨率限制在大约 (8000, 8000) 以避免消耗太多内存，在给定城市范围直径（100 到 120 公里）的情况下提供 15 米的精度。
- 形式上，POI 由集合 P = {p1, p2 …, pn} 表示。每个 POI pi 被定义为一个元组 ⟨t, T, (x, y)⟩，包含地理位置 (x, y) 和分类标签 t 和 T 。类别标签 T ，例如教育、交通和生活服务提供了更广泛的分类级别，而类别标签 t ，例如图书馆、公交车站和邮局提供了更精细的分类级别。在我们的 POI 数据中，我们有 113 个类别，分为 12 个类别。要分析的目标绩效衡量标准表示为 M 。用于计算 POI 的语义文本相似性的语料库和性能度量表示为 CM 和 CP。生成的语义图DM是表示每个地理位置的测量得分的二维密度场。 D 是通过组合中间类级别密度图 Dt 生成的。 SemanticMap 的整体流程可以表示为 **(P, M, CM, CP) → DM** ，如图 1 所示。我们的流程构建如下：
1.  数据预处理：为了确保只使用有用的信息并方便用户交互和评估，我们通过过滤琐碎的项目对 POI 数据进行预处理，并将 POI 分为 12 类。我们改进 TAZ 边界以避免交叉或重叠。
2. 语义贡献测量：为了量化不同 POI 对 M 的贡献，我们使用词典定义和上下文文本构建 POI 和 M 的语料库，然后计算它们的语义相似度
3. 语义地图生成：为了准确反映不同 POI 的影响范围和对性能指标的语义贡献，我们提出 SAKDE 作为 KDE 的改进，根据 POI 每个流量分析区域的本地密度及其语料库的语义文本自适应设置内核带宽和权重与绩效衡量的相似之处
4. 交互式视觉分析：为了方便公众对城市绩效进行分析，我们设计了一个实时视觉分析系统，支持语义地图的区域查询和跨测量比较。

## SEMANTICMAP
### Data Pre-processing
- POI 过滤。我们关注中国上海的POI数据，可以从百度地图2公开获得。原始数据包含大约 460,000 个 POI，分为 122 个类别。我们**排除影响较小的 POI**（例如楼梯、电梯和垃圾桶）以及那些通常被视为较大建筑物或结构的组成部分的 POI。桥梁和道路也被拆除，因为它们更普遍地被视为用于导航目的的交通基础设施而不是目的地。这是通过删除特定类别的 POI 并对 POI 名称应用基于关键字的过滤来实现的。
- POI 分类。过滤后，我们剩下 113 个 POI 类别。然后，我们将这些类别**组织成更广泛的分类级别**的类别。我们按照地形测量 3 提供的方案建立分类法。虽然官方地形测量方案包括 10 个类别，但我们通过将教育和健康类别分为教育和医疗保健来进一步细致化其结构，以更好地反映它们在功能和语义上的差异。我们还添加了“住宅”类别，该类别在原始地形测量方案中未找到，但在我们的 POI 数据中很常见。其他类别保持不变。总共有 12 个类别。然后，我们手动将 POI 类别分配到相应的类别。类别列表和一些示例类如图 3 所示。详细的分类可以在附录中找到。
- TAZ 划分 我们根据 OpenStreetMap 4 获得的道路网络数据来划分 TAZ。我们选择所有主要道路，包括高速公路以及 OSM 代码为 511x 的国家、地区和地方道路作为边界。我们在 ArcGIS Pro 中使用要素到栅格和栅格到面的转换，**从道路网络形状文件创建 TAZ 边界**。然后，我们通过应用 GEOS MakeValid 算法修复无效的自相交多边形 [73]。该算法将自相交的 TAZ 分割成多个有效部分。应用该算法后，我们观察到 277 个 TAZ 表现出重叠区域。我们手动删除它们，总共有 5677 个 TAZ

### Corpus Construction
- 拥有代表性语料库对于语义地图的质量至关重要，因为它是量化 POI 对不同度量的语义贡献的基础。我们将性能测量的语料库表示为 CM，将不同 POI 类别的语料库表示为 CP = {CPi}|t| 1 ，其中 |t|是 POI 类别的数量。使用定义句子来导出更好的句子嵌入来进行相似性测量，我们使用**定义句子和上下文文本构建我们的语料库。** POI 和绩效指标的定义语句均从 WordNet Synsets [75] 中检索。每个 Synset 代表一个概念或含义，并包含一组同义词。我们使用 POI 类名和性能指标名称查询 Synset，并提取相关含义作为定义句子。例如，POI 类 Gym 的定义句子是“为运动或体育训练配备的体育设施”。
	- 对于上下文文本，我们从基于位置的社交媒体应用程序收集文本用户评论，并选择可以描述 CP POI 功能的评论。
	- 对于CM，我们收集相关网页，包括博客、白皮书、游记、网站和相关研究论文作为初始文件。
- 在这里，每个文件可能描述多种城市绩效衡量标准。因此，在为特定的 M 构建语料库时，我们首先计算每个文档中 M 的词频 F，然后根据 F 对文档进行排序，然后选择前 50% 的文档作为候选文档。候选文档仍然包含不相关的信息，例如广告或表格。为了排除这些信息，我们将候选文档分成单独的句子 {S}in，并选择所有提及 M 的句子 Sn 及其上下文句子 {Si||i − n| ≤ 2}，作为 M 的最终语料库。这里，n表示上下文窗口大小
- 语料库构建过程如图 4 所示。我们总共收集了 1,175 条用户评论（翻译成英文后 238k 词）作为 CM，以及 113 个文档（总共 594k 词，经过过滤和上下文提取后 20k 词）作为 CP，提供绩效衡量和 POI 的综合表示。

### Semantic Textual Similarity Measurement
- 为了测量测量语料库和 POI 之间的语义文本相似性，我们利用预先训练的语言模型 DistilRoBERTa [18]，它是 RoBERTa [26] 模型的精炼版本，具有更快的速度和更低的内存使用量。该模型在 10 亿个句子对数据集上进行微调，并预测一组随机采样句子中的哪个句子与输入配对。根据 STS 基准 5 上的语义文本相似度，它在多个 SemEval 任务上的 Pearson 相关性方面实现了最先进的语义文本相似度性能。我们首先对语料库进行标记，以获取 POI 名称或度量名称 Tname 的标记、定义句子 Tdef 和上下文文本 Tcontext。模型的输入序列 I 表示为
- 然后，我们使用不同类 POI 数量的加权平均来计算每个 POI 类别 Ti 的语义文本相似度：

### Semantic-adaptive Kernel Density Estimation
- 度量的语义图 D 的生成包括两个步骤。首先，我们生成类级密度图 Dt。其次，结合Dt生成语义图D，如图5所示。我们提出语义自适应核密度估计（SAKDE）来生成Dt并在4.5节中描述融合过程

